{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Imports\n",
    "Import packages and load model parameters (uncertainties, levers, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from ema_workbench.analysis import (prim, dimensional_stacking)\n",
    "from ema_workbench import ema_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from ema_workbench import (\n",
    "    Model,\n",
    "    Policy,\n",
    "    ema_logging,\n",
    "    SequentialEvaluator,\n",
    "    MultiprocessingEvaluator,\n",
    "    Samplers,\n",
    ")\n",
    "from dike_model_function import DikeNetwork  # @UnresolvedImport\n",
    "from problem_formulation import get_model_for_problem_formulation\n",
    "from ema_workbench.analysis import parcoords\n",
    "\n",
    "\n",
    "def sum_over(*args):\n",
    "    return sum(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Enable logging\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Policy formulations\n",
    "Problem formulation 3 is selected, as we want to see the outcomes of each individual location to be able to zoom in on Zutphen.\n",
    "In the following cells the wanted policies can be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "used_problem_formulation = 3\n",
    "\n",
    "dike_model, planning_steps = get_model_for_problem_formulation(used_problem_formulation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function which sets everything to 0 by default\n",
    "def get_0_dict():\n",
    "    return {l.name: 0 for l in dike_model.levers}\n",
    "\n",
    "# Creates a Policy object from a dict and a (optional) name\n",
    "def create_policy(dict1, name=None):\n",
    "    return Policy(f\"Policy_{name}\", **dict(get_0_dict(), **dict1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the following policies formulations:\n",
    "- `switch` is to toggle room for river on and of\n",
    "- The number after `DikeIncrease` is again the timestep, the value assigned to the thing the heightening in decimeters.\n",
    "- Early Warning Systems can also be enabled, with `EWS_DaysToThreat`, which specifies the early warning time in days.\n",
    "\n",
    "See the implementation in problem_formulation.py (starting from line 35) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_policy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hanna\\Documents\\GitHub\\modelbased\\Open exploration.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanna/Documents/GitHub/modelbased/Open%20exploration.ipynb#ch0000009?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m switch \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanna/Documents/GitHub/modelbased/Open%20exploration.ipynb#ch0000009?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m ews_days \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m, \u001b[39m4\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hanna/Documents/GitHub/modelbased/Open%20exploration.ipynb#ch0000009?line=7'>8</a>\u001b[0m         pol_list\u001b[39m.\u001b[39mappend(create_policy({\u001b[39m\"\u001b[39m\u001b[39mA.3_DikeIncrease 0\u001b[39m\u001b[39m\"\u001b[39m: dm, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m_RfR 0\u001b[39m\u001b[39m\"\u001b[39m: switch, \u001b[39m\"\u001b[39m\u001b[39mEWS_DaysToThreat\u001b[39m\u001b[39m\"\u001b[39m: ews_days},\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hanna/Documents/GitHub/modelbased/Open%20exploration.ipynb#ch0000009?line=8'>9</a>\u001b[0m                                     name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDike_\u001b[39m\u001b[39m{\u001b[39;00mdm\u001b[39m}\u001b[39;00m\u001b[39mdm_RfR_\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mswitch\u001b[39m}\u001b[39;00m\u001b[39m_EWS_\u001b[39m\u001b[39m{\u001b[39;00mews_days\u001b[39m}\u001b[39;00m\u001b[39md\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_policy' is not defined"
     ]
    }
   ],
   "source": [
    "pol_list = []\n",
    "\n",
    "#Policies are created with a loop\n",
    "for dm in [0, 10]:\n",
    "    for location in [2]:\n",
    "        for switch in [0,1]:\n",
    "            for ews_days in [0, 4]:\n",
    "                pol_list.append(create_policy({\"A.3_DikeIncrease 0\": dm, f\"{location}_RfR 0\": switch, \"EWS_DaysToThreat\": ews_days},\n",
    "                                            name=f\"Dike_{dm}dm_RfR_{location}{switch}_EWS_{ews_days}d\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Run the model (or load the data)\n",
    "In the next cell the model is ran (if `use_pickle1 = False`) and the new results data is saved, or, if `use_pickle1 = True`, the saved results data is loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# True, use results in pickle file; False, run MultiprocessingEvaluator\n",
    "use_pickle1 = True\n",
    "\n",
    "if use_pickle1:\n",
    "    with open('data/formulation_results.pickle', 'rb') as filehandler:\n",
    "        results = pickle.load(filehandler)\n",
    "\n",
    "else:\n",
    "    # pass the policies list to EMA workbench experiment runs\n",
    "    n_scenarios = 15000\n",
    "    with MultiprocessingEvaluator(dike_model, n_processes=10) as evaluator:\n",
    "        results = evaluator.perform_experiments(n_scenarios, pol_list, uncertainty_sampling=Samplers.LHS)\n",
    "\n",
    "    # Save results in Pickle file\n",
    "    with open('data/policyresults.pickle', 'wb') as filehandler:\n",
    "        pickle.dump(results, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Clean up the results\n",
    "The data is cleaned, policies renamed, and new columns created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary to rename the policies\n",
    "#so we don't have to run everything again\n",
    "policy_dict = {\n",
    "    'Policy_Dike_0dm_RfR_20_EWS_0d': 'Policy 0', \n",
    "    'Policy_Dike_0dm_RfR_20_EWS_4d': 'Policy 1: EWS',\n",
    "    'Policy_Dike_0dm_RfR_21_EWS_0d': 'Policy 2: RfR', \n",
    "    'Policy_Dike_0dm_RfR_21_EWS_4d': 'Policy 3: RfR+EWS',\n",
    "    'Policy_Dike_10dm_RfR_20_EWS_0d': 'Policy 4: Dike',\n",
    "    'Policy_Dike_10dm_RfR_20_EWS_4d': 'Policy 5: Dike+EWS',\n",
    "    'Policy_Dike_10dm_RfR_21_EWS_0d': 'Policy 6: Dike+RfR', \n",
    "    'Policy_Dike_10dm_RfR_21_EWS_4d': 'Policy 7: Dike+RfR+EWS'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create a dataframe from outcomes, and add the policy column to it\n",
    "exp, out = results\n",
    "df = pd.DataFrame(out)\n",
    "\n",
    "#calculates the total costs for all locations\n",
    "a = df.columns[df.columns.str.contains('Costs')]\n",
    "df['Total Costs'] = df[a].sum(axis=1)\n",
    "#calculates deaths for all locations\n",
    "a = df.columns[df.columns.str.contains('Deaths')]\n",
    "df['Total Deaths'] = df[a].sum(axis=1)\n",
    "\n",
    "#renames the policies\n",
    "exp['policy'] = exp.policy.map(policy_dict)\n",
    "\n",
    "df[\"policy\"] = pd.DataFrame(exp)[\"policy\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/policyresults.pickle', 'wb') as filehandler:\n",
    "    pickle.dump(df, filehandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "In this section the data is visualized in several plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates pairplot and saves it in a png\n",
    "#plotting it in the notebook takes a while\n",
    "data=df.drop(['policy'], axis=1)\n",
    "sns_plot = sns.pairplot(df, hue='policy',  vars=data.columns )\n",
    "sns_plot.savefig('pairplot.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to create a boxplot the df first has to be \"melted\"\n",
    "df_melt = pd.melt(df, id_vars='policy')\n",
    "\n",
    "#15 subplots are created (even though only 14 were necessary)\n",
    "#it looks better in the report with three columns\n",
    "f, axes = plt.subplots(5, 3, sharex=True, figsize=(30, 50))\n",
    "\n",
    "#unique outcome list with a count to loop through and create a boxplot for each outcome\n",
    "unq_pol = df_melt.variable.unique()\n",
    "count = 0\n",
    "\n",
    "#creates boxplot\n",
    "axes = axes.flatten()\n",
    "for axs in axes:\n",
    "        if count<14:\n",
    "                print(axs)\n",
    "                sns.boxplot(x=\"policy\", y=\"value\", data=df_melt.loc[df_melt.variable ==unq_pol[count]], ax=axs)\n",
    "                axs.set_xticklabels(axs.get_xticklabels(),rotation=90)\n",
    "                axs.set_title(unq_pol[count])\n",
    "                count+=1\n",
    "        else:\n",
    "                pass\n",
    "f.savefig('boxplot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename to make the plots look nicer\n",
    "df.rename({\n",
    "       'A.1 Total Costs': '1.C', 'A.1_Expected Number of Deaths': '1.D',\n",
    "       'A.2 Total Costs': '2.C', 'A.2_Expected Number of Deaths': '2.D' , 'A.3 Total Costs': '3.C',\n",
    "       'A.3_Expected Number of Deaths': '3.D', 'A.4 Total Costs': '4.C',\n",
    "       'A.4_Expected Number of Deaths': '4.D', 'A.5 Total Costs': '5.C',\n",
    "       'A.5_Expected Number of Deaths': '5.D',  'RfR Total Costs': 'RfR', 'Expected Evacuation Costs':'Evac Costs'\n",
    "       },\n",
    "       axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_list = df['policy'].unique()\n",
    "\n",
    "#policies have to be renamed to numbers as plotly parallel coordinates are not able to take non numbers as color\n",
    "count=0\n",
    "for i in pol_list:\n",
    "    \n",
    "    df.loc[df.policy== i, 'policy'] = count\n",
    "    count+=1\n",
    "\n",
    "#get the limits of the variables    \n",
    "limits = parcoords.get_limits(df.iloc[:,:-1])\n",
    "\n",
    "#create a list for all dimensions to be plotted\n",
    "dimensionlist = []\n",
    "\n",
    "#dimensionlist is filled with names and limits \n",
    "for column in limits:\n",
    "    lower=0\n",
    "    upper=limits[column].iloc[1]\n",
    "    if upper>0:\n",
    "        dimensionlist.append(dict(range = [lower,upper],\n",
    "                label = column, values = df[column].values, tickformat = \"~g\"))\n",
    "    else:\n",
    "        dimensionlist.append(dict(range = [lower,0.1],\n",
    "                label = column, values = df[column].values, tickformat = \"~g\"))\n",
    "\n",
    "#plots parallel plot\n",
    "fig = go.Figure(data=\n",
    "    go.Parcoords(line = dict(color = df['policy'], showscale=True),\n",
    "                   dimensions= dimensionlist\n",
    "                             ))\n",
    "plt.savefig('explorationparallelplot.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prim, scenario discovery\n",
    "Thresholds are chosen for prim to select a smaller set of scenarios that will be analyzed. This set of scenarios consists of cases with expected deaths greater than zero and cases with total costs > 250 million euros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select prefered policies as mentioned in report\n",
    "exp_select = exp.loc[exp.policy.isin(['Policy 5: Dike+EWS', 'Policy 3: RfR+EWS','Policy 7: Dike+RfR+EWS'])]\n",
    "exp_select.reset_index(inplace=True)\n",
    "out_select = df.loc[exp.policy.isin(['Policy 5: Dike+EWS', 'Policy 3: RfR+EWS','Policy 7: Dike+RfR+EWS'])]\n",
    "out_select.reset_index(inplace=True)\n",
    "\n",
    "#clean up experiments\n",
    "x= exp_select[[\n",
    "       'A.0_ID flood wave shape', 'A.1_Bmax', 'A.1_Brate', 'A.1_pfail',\n",
    "       'A.2_Bmax', 'A.2_Brate', 'A.2_pfail', 'A.3_Bmax', 'A.3_Brate',\n",
    "       'A.3_pfail', 'A.4_Bmax', 'A.4_Brate', 'A.4_pfail', 'A.5_Bmax',\n",
    "       'A.5_Brate', 'A.5_pfail', 'discount rate 0', 'discount rate 1', 'policy'\n",
    "       ]]\n",
    "\n",
    "#create conditions\n",
    "y1=out_select['A.3_Expected Number of Deaths'] >0\n",
    "y2=out_select['A.3 Total Costs'] > 250e6\n",
    "y= np.logical_or(y1,y2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put y1 or y2 if you want them seperately: prim_alg = prim.Prim(x, y, threshold=0.7)\n",
    "prim_alg = prim.Prim(x, y, threshold=0.7)\n",
    "box1 = prim_alg.find_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.show_tradeoff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.inspect_tradeoff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.show_pairs_scatter()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box1.inspect(15, style='graph')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensional_stacking.create_pivot_plot(x, y)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bf2c32173ace6e8df916093214d79022fe1be3f368685e6950bae84362adba3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('simmaster')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
